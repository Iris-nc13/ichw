# 概论作业3 
# 异或运算的定义：
>1.异或是一个数学运算符。应用于逻辑运算。 
>2.**真异或**假的结果是真，**假异或**真的结果也是真，**真异或**真的结果是假，**假异或**假的结果是假。
   就是说两个值相 异结果为真。 
>异或的运算方法就是一个二进制运算： 
　　1^1=0   0^0=0 　1^0=1 　0^1=1    　两者相等为0,不等为1.

# 异或运算的法则：
>1. a ^ b = b ^ a 
　　2. a ^ b ^ c = a ^ (b ^ c) = (a ^ b) ^ c; 
　　3. d = a ^ b ^ c 可以推出 a = d ^ b ^ c. 
　　4. a ^ b ^ a = b.
  
## 问题1：有2n+1个数，只有一个单着，别的都是成对出现的，找出这个单着的数。（比如：2 1 3 2 1, 单着的数是3.）
>根据异或运算法则的二进制算法，易得相同的数字异或会为0（1^1=0 0^0=0）。而不同的数字异或就会为1（1^0=1 0^1=1） 任何数与0异或结果还是自己。
>在本题中，对2 1 3 2 1都异或一下便会得到这样的结果：
>相同的（2^2,1^1） 为0，
 剩下的3和0异或为自身3。
 这样就找到单独存在的数字了。
 
 
# 问题2:一个数列有101个整数，每个数范围为1-100，这101个数中有两个数是重复的，其他的都是唯一的，找到这个重复出现的数.
>本题也可套用异或法则进行解决：
 用异或法则二进制算法得知相同的数字异或结果会等于0 而不同的数字则会异或成1.题目已设定条件数字的范围是从1-100，故不存在任何数字与0异或得到0的结果，
>故只有当两个相同的数字进行异或才有可能出现0的结果。这样便可找出这两个重复的数字了。



# 详述通用的高速缓存存储器结构及工作原理
## 1.Cache是什么？
>Cache，高速缓存存储器，是计算机中介于寄存器与主存储器之间的器件，在工作中频繁的接受CPU的访问并读写Cache上的信息。

## 2.Cache有什么用？
![image](https://raw.githubusercontent.com/Iris-nc13/pictures/master/D87D73B8-4CF9-4D88-B090-BCFE05D27EC9.png)

>众所周知，CPU是电脑中最核心最金贵的部件，许多大难度计算都由CPU完成，因此CPU更新换代的速度极快，计算速度在不断的提高。但是与之相背的是，主存储器的读取数据的速度却无法与之相适应，这导致出现CPU处理速度过快以至于等待读取数据的现象，这使CPU的效率大打折扣。为了解决这一问题，Cache横空出世，它被用于CPU与主存储器之间，提前读取主存储器的数据放入自己的储存空间中，
等待CPU的访问；同时，Cache与CPU的读取速率比主存储器快的多，因此大大避免了CPU的等待情况的出现。相比于主存储器来说，Cache的存储空间更小，读取速度较高，起到了连接主存储器和CPU的桥梁作用。
 由于Cache的存取速率相当快，使得CPU的利用率大大提高，进而使整个系统的性能得以提升。

## 3.Cache的结构是什么样子

![2](https://raw.githubusercontent.com/Iris-nc13/pictures/master/8C3775D2-5EB0-427D-A046-83CC2348CA01.png)
该结构简化在平面中为：

![2](https://raw.githubusercontent.com/Iris-nc13/pictures/master/4F7CEAFB-0A59-43BB-9FA0-934A50712084.png)
>此两图为Cache的结构简图。（其中，Data为储存的数据，Tag为数据的地址信息，Valid则指出了该数据是否保留了有效位数，即能否有效被调用。）

![3](https://raw.githubusercontent.com/Iris-nc13/pictures/master/56E1334A-528C-4EC3-B86A-B0CF215922E5.png)
>事实上，主存和Cache的结构基本相同，都含有数据和地址，不过不同的是，在Cache中，多出了地址信息一栏，用于存储该数据对应物理内存的地址。当CPU访问Cache时，同时可以得到该数据在主存中的地址，从而得到物理内存中相应的数据。有效位的引入则是为了方便CPU更快的找到有效数据。在主存和缓存中，数据都是以（block）为单位进行存储的，假设主存有M块，缓存有C块，那么就有M>>C，也就是说，主存的存储量要远远大于缓存的存储量。 而对于被从主存中提取并放入缓存的数据来说，其在主存的数据与在缓存的数据完全相同，因此只要地址信息准确，CPU可以直接从Cache中进行读取到正确的数据并进行读写，但由于主存和缓存的块（block）的大小不同，因此如果数据过大，可能无法完整的放入缓存内，此时便需要CPU访问主存。

##4.Cache是如何工作的？

>1. 局部性原理与二八法则
>**时间局部性**：时间局部性指的是：被引用过一次的存储器位置在未来会被多次引用（通常在循环中）。
>**空间局部性**：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。
>此外还有**程序的局部性原理**：也就是我们常说的二八法则，一段程序中执行频率最高的代码往往只有20%，80%的代码很少用到，而这20％的代码完成了整个程序80%的功能。

>2. 命中与未命中
>刚才讲到，由于缓存的存储空间远小于内存的存储空间，势必无法储存所有的数据。因此我们规定，当CPU访问缓存时，如果需要的数据在Cache内，则成为**命中**；若不在Cache内，则称为**未命中**。
 同时，定义**命中率**：即一段时间内，命中的次数与该时间内CPU访问的总次数的比值。由此我们知道，Cache的命中率当然是越高越好。一般来说，Cache的容量越大，命中率越高。其次，命中率也与算法息息相关。

>3. 缓存的数据与主存的数据一一对应，因此存在映射关系，其具体大致分为如下几种：

>**a.全相连映射**
>主存中任何一个块均可以映像装入到Cache中的任何一个块的位置上。主存地址分为块号和块内地址两部分，Cache地址也分为块号和块内地址。Cache的块内地址部分直接取自主存地址的块内地址段。主存块号和Cache块号不相同，Cache块号根据主存块号从块表中查找。Cache保存的各数据块互不相关，Cache必须对每个块和块自身的地址加以存储。当请求数据时，Cache控制器要把请求地址同所有的地址加以比较，进行确认。
>主存地址格式：主存块号+块内偏移地址
>cache地址格式： cache行号+行内偏移地址
>cache标记tag：主存块号
>映射过程（地址变换过程）：
>CPU提供一内存地址给cache，cache中的“控制逻辑”将“主存地址格式”中的“主存块号”与cache中所有行的标记tag进行同时比较。
>如果存在相同的，即表示“命中”，根据“块内偏移地址”找到相应的字。
>如果不存在相同的，即表示“未命中”，那么将会到主存中寻找。

>**b.直接映射**
>把主存分成若干区，每区与Cache大小相同。区内分块，主存每个区中块的大小和Cache中块的大小相等，主存中每个区包含的块的个数与Cache中块的个数相等。任意一个主存块只能映像到Cache中唯一指定的块中，即相同块号的位置。主存地址分为三部分：区号、块号和块内地址，Cache地址分为：块号和块内地址。直接映像方式下，数据块只能映像到Cache中唯一指定的位置，故不存在替换算法的问题。它不同于全相连Cache，地址仅需比较一次。
>主存地址格式：主存组号+组内块号+块内偏移地址
>cache地址格式：cache行号+行内偏移地址
>cache标记tag：映射到该行的主存块的主存地址的“组号”
>映射过程（地址变换过程）：
>CPU提供一内存地址给cache，相关的逻辑根据内存地址中的“组内块号”确定该主存块如果发生拷贝会被拷贝到哪一行；然后，将内存地址中的“主存组号”与上步确定的cache行的标记tag进行比较，如果存在相同的即“命中”，如果不存在相同的即“未命中”。

>**c.组相连映射**
>组相连映像是前两种方式的折衷。主存按Cache容量分区，每个区分为若干组，每组包含若干块。Cache也进行同样的分组和分块。主存中一个组内的块数与Cache中一个组内的块数相等。组间采用直接方式，组内采用全相连方式。组的容量＝1时，即直接映像，组的容量＝整个Cache的容量时，即全相连映像。Cache的存在对于程序员透明，Cache的地址变换和数据块的替换算法都采用硬件实现。
>主存地址格式：主存组号+组内块号+块内偏移地址
>cache地址格式：cache组号+组内行号+行内偏移地址
>cache标记tag：组号
>映射过程（地址变换过程）：
CPU提供一内存地址给cache，相关逻辑根据地址中的“组内块号”部分确定主存块如果发生拷贝将会被放置到cache的哪一组中；
然后，将地址中的“主存组号”与上步所确定的那一组中所有行的tag同时进行比较，如果存在相同的即“命中”，如果不存在相同的即为“未命中”。

>**Cache具体的工作过程**
>简单来说，工作原理是把CPU最近可能用到的少量信息，可能是数据，也可能是指令，从内存复制到CACHE中，使CPU能够更高速的访问这些数据，提高工作效率。

>首先CPU对Cache发出访问，通过主存Cache地址映射变换机制没来判断该数据是否命中（判断方法如上文所示）：
>若**命中**，则直接从Cache读取；
>若需要调入数据则需要先判断，缓存中是否还存在空间能够提供给将要调入的数据：
>如果**存在**空间，则直接调入即可；如果**不存在**空间，则需要采取数据的替换策略，将缓存中的一部分数据调出以腾出空间，此时便用到替换算法。（某些Cache为了提高访问数据的速度，会利用数据总线，当Cache未命中时，CPU会通过主线同时从内存中调用数据）
>当然，这些还没有完，在Cache的不断改进下，现在采用的大多是多级缓存。即采用多个Cache同时工作的方法，在CPU和主存之间设立多个Cache。效率最高的Cache直接设立在CPU内部，其次在CPU外部以及主存外部再各设立一个Cache，因此现在的计算机大多具有三个以上的Cache。当然，如果是多核处理器（CPU），那么每一个CPU都会有自己独立的Cache，以提高工作效率（但同时miss率会上升），以及存在多个CPU共用的Cache。
>**那么这些Cache如何分工呢？**
>这就用到了刚刚提到的局域性和二八规则。这些由内至外的Cache一般来说他们的容量是不断减小到的，我们可以根据二八规则将这20%的常用代码缓存到cpu一级缓存或者二级缓存中，因为cpu中的cache的速度和cpu的**时钟频率**最接近，这样就可以提高程序运行的速度，剩下的Cache则要根据局域性原理，将所用的数据以及该数据相邻的数据都储存到相应的缓存中。

>对于Cache来说，采用了两种改写数据的方式，分别说 **写直达法** 和 **写返回法** 。

>**写直达法（write--through）**：又称全写法，写透。是当cache写命中时，Cache与主存同时发生写修改。这种策略显然较好地维护了Cache与主存的内容一致性，但这并不等于说全部解决了一致性问题。例如在多处理器系统中各CPU都有自己的Cache，一个主存块若在多个cache中都有一份拷贝的话，某个CPU以写直达法来修改它的cache和主存时，其它Cache中的原拷贝就过时了。即使在单处理器系统中，也有I／O设备不经过Cache向主存写入的情况。总之，仍要关注一致性问题。

>**写回法（write--back）**：当CPU对Cache写命中时，只修改Cache的内容不立即写入主存，只当此行被换出时才写回主存。这种策略使Cache在CPU－主存之间，不仅在读方向而且在写方向上都起到高速缓存作用。对一Cache行的多次写命中都在Cache中快速完成修改， 只是需被替换时才写回速度较慢的主存，减少了访问主存的次数从而提高了效率。为支持这种策略，每个Cache行必须配置一个修改位，以反映此行是否被CPU修改过。当某行被换出时，根据此行修改位为1还是为0，
决定是将该行内容写回主存还是简单地弃之而不顾。但同时写回法更加难以保证缓存数据和主存数据的一致性，因此可能会导致数据的丢失或错误。 
>总的来说，Cache的存在大大提高了计算机的性能，为CPU提供了更好的工作环境，是计算机必不可少的部件之一！
